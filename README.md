# LLM Working: Visualizing Language Model Processing

This project demonstrates how a Language Model (LLM) works, from input processing to embedding generation and response creation. It's an educational tool designed to help users understand the inner workings of large language models.

## Features

- Tokenization visualization
- TF-IDF vectorization and heatmap
- Dimensionality reduction using PCA
- Simulated attention mechanism
- Step-by-step explanation of LLM processing

## Installation

To run this project, you need Python 3.7+ and the following libraries:

## Usage

1. Clone the repository:

git clone https://github.com/sohail000/llm-working.git

3. Run the Streamlit app:

   3. Open your web browser and navigate to the URL provided by Streamlit (usually http://localhost:8501).

4. Enter your text in the input area and explore the visualizations and explanations.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is open source and available under the [MIT License](LICENSE).
